{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4481d2fe",
   "metadata": {},
   "source": [
    "**YOLO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7509cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating Self-Captured Dataset ---\n",
      "Ultralytics 8.4.9  Python-3.10.11 torch-2.11.0.dev20260130+cu130 CUDA:0 (NVIDIA GeForce RTX 5060, 8150MiB)\n",
      "YOLO11n summary (fused): 101 layers, 2,582,932 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 233.380.1 MB/s, size: 61.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning H:\\TCV_PROJECT\\dataset\\kagel img\\labels\\val... 1467 images, 4 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1467/1467 3.1Kit/s 0.5s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: H:\\TCV_PROJECT\\dataset\\kagel img\\labels\\val.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 92/92 8.5it/s 10.8s0.1s\n",
      "                   all       1467       4583      0.189      0.198     0.0861     0.0528\n",
      "               plastic        474       1547      0.301     0.0922     0.0973     0.0588\n",
      "                 paper        166        363     0.0675      0.433     0.0597     0.0352\n",
      "                 metal        592       1693      0.265      0.216      0.136     0.0872\n",
      "                 glass        416        980      0.124      0.052     0.0516     0.0299\n",
      "Speed: 1.3ms preprocess, 1.9ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mH:\\TCV_PROJECT\\runs\\detect\\val12\u001b[0m\n",
      "Precision: 0.1892\n",
      "Recall: 0.1981\n",
      "mAP50: 0.0861\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 加载已经修复好的模型\n",
    "model = YOLO(r'H:\\TCV_PROJECT\\best.pt')\n",
    "\n",
    "print(\"--- Evaluating Self-Captured Dataset ---\")\n",
    "metrics_self = model.val(data='Public.yaml')\n",
    "\n",
    "\n",
    "print(f\"Precision: {metrics_self.results_dict['metrics/precision(B)']:.4f}\")\n",
    "print(f\"Recall: {metrics_self.results_dict['metrics/recall(B)']:.4f}\")\n",
    "print(f\"mAP50: {metrics_self.results_dict['metrics/mAP50(B)']:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. 基础配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet_val_path = 'H:/TCV_PROJECT/dataset/self capture img/resnet_val_format'\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. 加载模型架构\n",
    "model_resnet = models.resnet50(weights=None)\n",
    "model_resnet.fc = nn.Linear(model_resnet.fc.in_features, 4)\n",
    "\n",
    "# 【关键：如果你有权重文件，取消下面这行的注释】\n",
    "# model_resnet.load_state_dict(torch.load(r'H:\\TCV_PROJECT\\resnet_best.pth'))\n",
    "\n",
    "model_resnet = model_resnet.to(device).eval()\n",
    "\n",
    "# 3. 运行评估\n",
    "test_set = datasets.ImageFolder(resnet_val_path, transform=data_transforms)\n",
    "loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in loader:\n",
    "        outputs = model_resnet(inputs.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "print(\"\\n[ResNet50] Results:\")\n",
    "print(classification_report(y_true, y_pred, target_names=test_set.classes)) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe7a65",
   "metadata": {},
   "source": [
    "**ResNet50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. 基础配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet_val_path = 'H:/TCV_PROJECT/dataset/self capture img/resnet_val_format'\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. 加载模型架构\n",
    "model_resnet = models.resnet50(weights=None)\n",
    "model_resnet.fc = nn.Linear(model_resnet.fc.in_features, 4)\n",
    "\n",
    "# 【关键：如果你有权重文件，取消下面这行的注释】\n",
    "# model_resnet.load_state_dict(torch.load(r'H:\\TCV_PROJECT\\resnet_best.pth'))\n",
    "\n",
    "model_resnet = model_resnet.to(device).eval()\n",
    "\n",
    "# 3. 运行评估\n",
    "test_set = datasets.ImageFolder(resnet_val_path, transform=data_transforms)\n",
    "loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in loader:\n",
    "        outputs = model_resnet(inputs.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "print(\"\\n[ResNet50] Results:\")\n",
    "print(classification_report(y_true, y_pred, target_names=test_set.classes)) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26948824",
   "metadata": {},
   "source": [
    "**HOG + SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50484d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 路径配置\n",
    "test_path = 'H:/TCV_PROJECT/dataset/self capture img/resnet_val_format'\n",
    "categories = ['glass', 'metal', 'paper', 'plastic']\n",
    "\n",
    "# 提取 HOG 特征\n",
    "def extract_hog(folder_path):\n",
    "    features, labels = [], []\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    for idx, cat in enumerate(categories):\n",
    "        p = os.path.join(folder_path, cat)\n",
    "        for img_n in os.listdir(p):\n",
    "            img = cv2.imread(os.path.join(p, img_n))\n",
    "            if img is None: continue\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            features.append(hog.compute(gray).flatten())\n",
    "            labels.append(idx)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c992580b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f741d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
